{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: KNN\n",
    "\n",
    "For this part of assignment, you are tasked to implement KNN algorithm and test it on the a subset of CIFAR10 dataset.\n",
    "\n",
    "You sould run the whole notebook and answer the question in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.answer import save_answer, dump_answers\n",
    "answers = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset\n",
    "\n",
    "Since CIFAR10 is a relatively large dataset, and KNN is quite time-consuming, we only used a small subset of CIFAR10 for KNN.\n",
    "\n",
    "> **Note:**  \n",
    "> Before running the cell below, please make sure that you have already run `get_datasets.py`.  \n",
    "> See the README for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_processing import get_cifar10_data\n",
    "\n",
    "# Use a subset of CIFAR10 for KNN assignments\n",
    "dataset = get_cifar10_data(subset_train=5000, subset_val=250, subset_test=500)\n",
    "\n",
    "print(dataset.keys())\n",
    "print(\"Training Set Data  Shape: \", dataset[\"x_train\"].shape)\n",
    "print(\"Training Set Label Shape: \", dataset[\"y_train\"].shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation (40%)\n",
    "\n",
    "You need to implement the KNN method in `algorithms/knn.py`. You need to fill in the prediction function(since the training of KNN is just remembering the training set).\n",
    "\n",
    "For KNN implementation, you are tasked to implement two version of it.\n",
    "\n",
    "* Two Loop Version: use one loop to iterate through training samples and one loop to iterate through test samples\n",
    "* One Loop Version: use one loop to iterate through test samples and use broadcast (https://numpy.org/doc/stable/user/basics.broadcasting.html) feature of numpy to calculate all the distance at once\n",
    "\n",
    "For the distance function, please use the Euclidean distance between samples.\n",
    "\n",
    "> **Notes:**  \n",
    "> * It is possible to build a Fully Vectorized Version without explicit for loop to calculate the distance, but you do not have to do it in this assignment. You could use the fully vectorized version to replace the loop versions as well.\n",
    "> * The speed may vary by machine, and a one-loop method is not always faster than a two-loop method, which is okay.\n",
    "> * If your implementation is correct, you should typically see an accuracy above **25%** for this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithms import KNN\n",
    "\n",
    "knn = KNN(num_class=10)\n",
    "knn.train(\n",
    "    x_train=dataset[\"x_train\"],\n",
    "    y_train=dataset[\"y_train\"],\n",
    "    k=5,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the time consumption of different method\n",
    "\n",
    "In this section, you will test your different implementation of KNN method, and compare their speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.evaluation import get_classification_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two Loop Version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "c_t = time.time()\n",
    "prediction = knn.predict(dataset[\"x_test\"], loop_count=2)\n",
    "print(\"Two Loop Prediction Time:\", time.time() - c_t)\n",
    "\n",
    "two_loop_acc = get_classification_accuracy(prediction, dataset[\"y_test\"])\n",
    "print(\"Test Accuracy:\", two_loop_acc)\n",
    "\n",
    "answers = save_answer(answers, \"Q1\", two_loop_acc, \"float\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Loop Version: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "c_t = time.time()\n",
    "prediction = knn.predict(dataset[\"x_test\"], loop_count=1)\n",
    "print(\"One Loop Prediction Time:\", time.time() - c_t)\n",
    "\n",
    "one_loop_acc = get_classification_accuracy(prediction, dataset[\"y_test\"])\n",
    "print(\"Test Accuracy:\", one_loop_acc)\n",
    "\n",
    "answers = save_answer(answers, \"Q2\", one_loop_acc, \"float\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your different implementation should output the exact same result (accuracy).**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test different Hyper-parameter (20%)\n",
    "\n",
    "For KNN, there is only one hyper-parameter of the algorithm: How many nearest neighbour to use(**K**).\n",
    "\n",
    "Here, you are provided the code to test different k for the same dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "\n",
    "k_candidates = [1, 3, 5, 10, 20, 50]\n",
    "for k_cand in k_candidates:\n",
    "    prediction = knn.predict(x_test=dataset[\"x_test\"], k=k_cand)\n",
    "    acc = get_classification_accuracy(prediction, dataset[\"y_test\"])\n",
    "    accuracies.append(acc)\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"K\")\n",
    "plt.plot(k_candidates, accuracies)\n",
    "plt.show()\n",
    "\n",
    "answers = save_answer(answers, \"Q3\", accuracies, \"float_list\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inline Question 1 (10%):\n",
    "\n",
    "Please describe the output results you get above, including two loop/one loop/different k, and provide some explanation as well.\n",
    "\n",
    "\n",
    "### Your Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try different feature representation (20%)\n",
    "\n",
    "Since machine learning method rely heavily on the feature extraction, you will see how different feature representation affect the performance of the algorithm in this section. \n",
    "\n",
    "You are provided the code about using **HOG** descriptor to represent samples in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_processing import get_cifar10_data\n",
    "from utils.data_processing import HOG_preprocess\n",
    "from functools import partial\n",
    "\n",
    "# Delete previous dataset to save memory\n",
    "del dataset\n",
    "del knn\n",
    "\n",
    "# Use a subset of CIFAR10 for KNN assignments\n",
    "hog_p_func = partial(\n",
    "    HOG_preprocess,\n",
    "    orientations=9,\n",
    "    pixels_per_cell=(4, 4),\n",
    "    cells_per_block=(1, 1),\n",
    "    visualize=False,\n",
    "    channel_axis=2\n",
    ")\n",
    "dataset = get_cifar10_data(\n",
    "    feature_process=hog_p_func, subset_train=5000, subset_val=250, subset_test=500\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNN(num_class=10)\n",
    "knn.train(\n",
    "    x_train=dataset[\"x_train\"],\n",
    "    y_train=dataset[\"y_train\"],\n",
    "    k=5,\n",
    ")\n",
    "hog_accuracies = []\n",
    "\n",
    "k_candidates = [1, 3, 5, 10, 20, 50]\n",
    "for k_cand in k_candidates:\n",
    "    prediction = knn.predict(x_test=dataset[\"x_test\"], k=k_cand)\n",
    "    acc = get_classification_accuracy(prediction, dataset[\"y_test\"])\n",
    "    hog_accuracies.append(acc)\n",
    "\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"K\")\n",
    "plt.plot(k_candidates, hog_accuracies)\n",
    "plt.show()\n",
    "\n",
    "answers = save_answer(answers, \"Q4\", hog_accuracies, \"float_list\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inline Question 2 (10%):\n",
    "\n",
    "Please describe the output results you get here, compare with the results you get in the previous section, and provide some explanation as well.\n",
    "\n",
    "### Your Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survey\n",
    "\n",
    "### Question:\n",
    "\n",
    "How many hours did you spend on assignment 1?\n",
    "\n",
    "### Your Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting\n",
    "\n",
    "### Exporting Answer\n",
    "We will now export the saved answers to a .txt file. Ensure the answer dictionary is up to date. If unsure, restart the kernel and rerun the notebook before exporting. Do not change the filename here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_answers(\n",
    "    answers,\n",
    "    expected_keys=[\"Q1\", \"Q2\", \"Q3\", \"Q4\"],\n",
    "    filename=\"answers_hw1.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting Notebook into PDF\n",
    "\n",
    "Now we will export the current notebook to a PDF file. You can run the cell below. If it fails, you can also export the notebook as a PDF directly from the Jupyter web interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to pdf knn.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŽ‰ Submitting to Gradescope\n",
    "\n",
    "Congrats on finishing **Assignment 1**!\n",
    "\n",
    "You will see two submission entries on Gradescope: **Assignment 1** and **Assignment 1 â€“ Code**.\n",
    "\n",
    "- **Assignment 1**  \n",
    "  Submit `answers_hw1.txt` and the notebook PDF (e.g., `knn.pdf`).  \n",
    "  No zip file is needed. Upload **one `.txt` file and one `.pdf` file**.\n",
    "\n",
    "- **Assignment 1 â€“ Code**  \n",
    "  Submit `algorithms/knn.py`.  \n",
    "  No zip file is needed. This should be **a single Python file**.\n",
    "\n",
    "After you submit **Assignment 1**, you will see format check results. Please make sure that your `answers_hw1.txt` passes all the format checks shown there. If all format checks pass, your submission format is correct and you should be all set.\n",
    "\n",
    "The **correctness score** will be released later when the assignment scores are officially published."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
